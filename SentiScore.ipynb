{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60af0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from SentiCR.SentiCR import SentiCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c54ee",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "afb41061",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/erdemdemir/DataspellProjects/empiricalSE/data/golang/Aug2020-Sep2020/golang_Aug2020-Sep2020.xml.out'\n",
    "df_original = pd.read_xml(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84904639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       conversation_id                          ts       user  \\\n4                  1.0  2020-08-01T00:01:15.595000    Samarie   \n5                  1.0  2020-08-01T00:01:22.227000    Samarie   \n6                  1.0  2020-08-01T00:02:50.586000     Cephas   \n7                  1.0  2020-08-01T00:02:51.116000     Cephas   \n8                  1.0  2020-08-01T00:02:55.357000     Cephas   \n...                ...                         ...        ...   \n60078           1915.0  2020-09-30T18:06:13.071000  Cristofor   \n60079           1915.0  2020-09-30T18:16:02.925000    Samarie   \n60080           1914.0  2020-09-30T18:24:10.424000  Cristofor   \n60081           1915.0  2020-09-30T18:24:27.760000  Cristofor   \n60082           1915.0  2020-09-30T18:25:55.416000  Cristofor   \n\n                                                    text  \n4                            {{ with .Data }} also works  \n5               if .Data is invalid it won't be rendered  \n6                                                     ah  \n7                                                   true  \n8                                    okay okay thank you  \n...                                                  ...  \n60078                      then ill check freenode later  \n60079               I unironically prefer IRC over Slack  \n60080           as long as its not in the browser me too  \n60081       i made my GUI build unchanged for Android! ðŸ˜„  \n60082  it was the right combination of build tool (go...  \n\n[60079 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversation_id</th>\n      <th>ts</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>2020-08-01T00:01:15.595000</td>\n      <td>Samarie</td>\n      <td>{{ with .Data }} also works</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>2020-08-01T00:01:22.227000</td>\n      <td>Samarie</td>\n      <td>if .Data is invalid it won't be rendered</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>2020-08-01T00:02:50.586000</td>\n      <td>Cephas</td>\n      <td>ah</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>2020-08-01T00:02:51.116000</td>\n      <td>Cephas</td>\n      <td>true</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.0</td>\n      <td>2020-08-01T00:02:55.357000</td>\n      <td>Cephas</td>\n      <td>okay okay thank you</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60078</th>\n      <td>1915.0</td>\n      <td>2020-09-30T18:06:13.071000</td>\n      <td>Cristofor</td>\n      <td>then ill check freenode later</td>\n    </tr>\n    <tr>\n      <th>60079</th>\n      <td>1915.0</td>\n      <td>2020-09-30T18:16:02.925000</td>\n      <td>Samarie</td>\n      <td>I unironically prefer IRC over Slack</td>\n    </tr>\n    <tr>\n      <th>60080</th>\n      <td>1914.0</td>\n      <td>2020-09-30T18:24:10.424000</td>\n      <td>Cristofor</td>\n      <td>as long as its not in the browser me too</td>\n    </tr>\n    <tr>\n      <th>60081</th>\n      <td>1915.0</td>\n      <td>2020-09-30T18:24:27.760000</td>\n      <td>Cristofor</td>\n      <td>i made my GUI build unchanged for Android! ðŸ˜„</td>\n    </tr>\n    <tr>\n      <th>60082</th>\n      <td>1915.0</td>\n      <td>2020-09-30T18:25:55.416000</td>\n      <td>Cristofor</td>\n      <td>it was the right combination of build tool (go...</td>\n    </tr>\n  </tbody>\n</table>\n<p>60079 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_original[4:].drop(['team_domain', 'channel_name', 'start_date', 'end_date'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabe419",
   "metadata": {},
   "source": [
    "### SentiCR preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "166ff0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackOverflow Reading data from oracle..\n",
      "Training classifier model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ani', 'continu', 'deleg', 'doe', 'doubl', 'dure', 'els', 'endwhil', 'extend', 'implement', 'includ', 'interfac', 'namespac', 'nativ', 'nowwhil', 'onc', 'ourselv', 'overrid', 'packag', 'privat', 'protect', 'rais', 'readon', 'requir', 'sign', 'synchron', 'themselv', 'tri', 'veri', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training used 4.96 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "sentiment_analyzer=SentiCR()\n",
    "def predict_sentiCR(df, column = 'first_message'):\n",
    "    begin=time.time()\n",
    "    sentences=df[column]\n",
    "    pred=[]\n",
    "    for sent in sentences:\n",
    "        score=sentiment_analyzer.get_sentiment_polarity(sent)\n",
    "        pred.append(score)\n",
    "    \n",
    "    end=time.time()\n",
    "    print('Prediction used {:.2f} seconds'.format(end-begin))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc7a89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "sentiCR_path = filename[-30:-8]+'-CR.csv'\n",
    "\n",
    "if exists(sentiCR_path):\n",
    "    df_sentiCR = pd.read_csv(sentiCR_path)\n",
    "else:\n",
    "    pred_full = predict_sentiCR(df, 'text')\n",
    "    df_sentiCR = df.copy()\n",
    "    df_sentiCR['sentiCR'] = Extract(pred_full)\n",
    "    df_sentiCR['sentiCR'] = df_sentiCR['sentiCR'].replace({2: -1})\n",
    "    df_sentiCR.to_csv(sentiCR_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "311d7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            tmp = df[df[r].notnull() & df[c].notnull()]\n",
    "            pvalues[r][c] = round(pearsonr(tmp[r], tmp[c])[1], 4)\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91610b9b",
   "metadata": {},
   "source": [
    "### Senti4SD preprocessing\n",
    "For the preprocessing of Senti4SD we do the sentiment score calculation outside this notebook file. Make sure yuo save the csv to predictions_senti4SD.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a3110cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use this dataframe to feed to the senti4SD repo\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                       Text\n4               {{ with .Data }} also works\n5  if .Data is invalid it won't be rendered\n6                                        ah\n7                                      true\n8                       okay okay thank you",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>{{ with .Data }} also works</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>if .Data is invalid it won't be rendered</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ah</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>true</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>okay okay thank you</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_senti4SD = df.copy()\n",
    "df_senti4SD = df_senti4SD.drop(['ts', 'conversation_id', 'user'], axis=1).rename(columns={\"text\": \"Text\"})\n",
    "df.index.name = 'ID'\n",
    "print('Use this dataframe to feed to the senti4SD repo')\n",
    "senti4SD_path = filename[-30:-8]+'-4SD.csv'\n",
    "df_senti4SD.to_csv(senti4SD_path, sep=';')\n",
    "df_senti4SD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c589282e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 152, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/0z/cvwxldvs5qjdzx5vn89pn9f40000gn/T/ipykernel_20121/3921877768.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0msenti4SD\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msenti4SD_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mby\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'ID'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'ID'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0msenti4SD\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'PREDICTED'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msenti4SD\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'PREDICTED'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'negative'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'neutral'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'positive'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    486\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    487\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mparser\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 488\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    489\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    490\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1045\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1046\u001B[0m         \u001B[0mnrows\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidate_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"nrows\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1047\u001B[0;31m         \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1048\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1049\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlow_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 223\u001B[0;31m                 \u001B[0mchunks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_low_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    224\u001B[0m                 \u001B[0;31m# destructive to chunks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_concatenate_chunks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mParserError\u001B[0m: Error tokenizing data. C error: Expected 1 fields in line 152, saw 2\n"
     ]
    }
   ],
   "source": [
    "senti4SD = pd.read_csv(senti4SD_path).sort_values(by=['ID']).set_index('ID')\n",
    "senti4SD['PREDICTED'] = senti4SD['PREDICTED'].replace({'negative': -1, 'neutral': 0, 'positive': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbfcfc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "senti4SD_df = df.copy()\n",
    "senti4SD_df['senti4SD'] = senti4SD['PREDICTED'].copy()\n",
    "senti4SD_df.to_csv(senti4SD_path)\n",
    "senti4SD_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}